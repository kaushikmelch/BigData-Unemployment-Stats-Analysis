{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e0732-6853-4fa7-b0ae-cf8f76bdd070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.sql import Window\n",
    "import re\n",
    "from pyspark.sql.functions import col, lag, concat_ws\n",
    "from haversine import haversine, Unit\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import json\n",
    "import requests\n",
    "file_path = \"Unemployment.xlsx\"  # \n",
    "unemployment = pd.read_excel(file_path, sheet_name=0)\n",
    "\n",
    "unemployment = unemployment.iloc[3:]\n",
    "unemployment.columns = unemployment.iloc[0]  \n",
    "unemployment = unemployment[1:]  \n",
    "unemployment = unemployment[~unemployment['FIPS_Code'].astype(str).str.endswith(\"000\")]\n",
    "unemployment.columns = unemployment.columns.str.strip()\n",
    "unemployment = unemployment.reset_index(drop=True)  # Reset the index\n",
    "\n",
    "selected_columns = [\n",
    "    \"FIPS_Code\", \"State\", \"Area_Name\",\n",
    "    \"Civilian_labor_force_2019\", \"Unemployed_2019\", \"Unemployment_rate_2019\",\n",
    "    \"Civilian_labor_force_2020\", \"Unemployed_2020\", \"Unemployment_rate_2020\",\n",
    "    \"Civilian_labor_force_2021\", \"Unemployed_2021\", \"Unemployment_rate_2021\",\n",
    "    \"Civilian_labor_force_2022\", \"Unemployed_2022\", \"Unemployment_rate_2022\"\n",
    "]\n",
    "\n",
    "\n",
    "unemployment = unemployment[selected_columns]\n",
    "\n",
    "unemployment.columns = [\n",
    "    \"FIPS_Code\", \"State\", \"Area_Name\",\n",
    "    \"Civilian_labor_force_2020\", \"Unemployed_2020\", \"Unemployment_rate_2020\",\n",
    "    \"Civilian_labor_force_2021\", \"Unemployed_2021\", \"Unemployment_rate_2021\",\n",
    "    \"Civilian_labor_force_2022\", \"Unemployed_2022\", \"Unemployment_rate_2022\",\n",
    "    \"Civilian_labor_force_2023\", \"Unemployed_2023\", \"Unemployment_rate_2023\"\n",
    "]\n",
    "# Reset the index\n",
    "unemployment = unemployment.reset_index(drop=True)\n",
    "\n",
    "state_abbreviations = {\n",
    "    \"AL\": \"Alabama\", \"AK\": \"Alaska\", \"AZ\": \"Arizona\", \"AR\": \"Arkansas\", \"CA\": \"California\",\n",
    "    \"CO\": \"Colorado\", \"CT\": \"Connecticut\", \"DE\": \"Delaware\", \"FL\": \"Florida\", \"GA\": \"Georgia\",\n",
    "    \"HI\": \"Hawaii\", \"ID\": \"Idaho\", \"IL\": \"Illinois\", \"IN\": \"Indiana\", \"IA\": \"Iowa\",\n",
    "    \"KS\": \"Kansas\", \"KY\": \"Kentucky\", \"LA\": \"Louisiana\", \"ME\": \"Maine\", \"MD\": \"Maryland\",\n",
    "    \"MA\": \"Massachusetts\", \"MI\": \"Michigan\", \"MN\": \"Minnesota\", \"MS\": \"Mississippi\", \"MO\": \"Missouri\",\n",
    "    \"MT\": \"Montana\", \"NE\": \"Nebraska\", \"NV\": \"Nevada\", \"NH\": \"New Hampshire\", \"NJ\": \"New Jersey\",\n",
    "    \"NM\": \"New Mexico\", \"NY\": \"New York\", \"NC\": \"North Carolina\", \"ND\": \"North Dakota\", \"OH\": \"Ohio\",\n",
    "    \"OK\": \"Oklahoma\", \"OR\": \"Oregon\", \"PA\": \"Pennsylvania\", \"RI\": \"Rhode Island\", \"SC\": \"South Carolina\",\n",
    "    \"SD\": \"South Dakota\", \"TN\": \"Tennessee\", \"TX\": \"Texas\", \"UT\": \"Utah\", \"VT\": \"Vermont\",\n",
    "    \"VA\": \"Virginia\", \"WA\": \"Washington\", \"WV\": \"West Virginia\", \"WI\": \"Wisconsin\", \"WY\": \"Wyoming\"\n",
    "}\n",
    "\n",
    "def expand_state_name(area_name):\n",
    "    if \",\" in area_name:\n",
    "        county, state_abbr = area_name.rsplit(\", \", 1)\n",
    "        state_full = state_abbreviations.get(state_abbr, state_abbr)\n",
    "        return f\"{county}, {state_full}\"\n",
    "    return area_name\n",
    "\n",
    "unemployment[\"Area_Name\"] = unemployment[\"Area_Name\"].apply(expand_state_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b98398d-0dfe-414f-876d-fce73eee42a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"lagdp1224.csv\"\n",
    "\n",
    "raw_data = pd.read_csv(file_path, skiprows=2)\n",
    "\n",
    "raw_data = raw_data.iloc[:, :5]\n",
    "\n",
    "\n",
    "cleaned_data = raw_data.dropna()\n",
    "cleaned_data = cleaned_data[~cleaned_data.isin(['--']).any(axis=1)]\n",
    "cleaned_data.columns = [\"Area_Name\", \"gdp_2020\", \"gdp_2021\", \"gdp_2022\",\"gdp_2023\"]\n",
    "\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60855dd-bb50-46f6-83e9-a13da02d0db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleaned_data.columns = [\"Area_Name\", \"gdp_2020\", \"gdp_2021\", \"gdp_2022\", \"gdp_2023\"]\n",
    "unemployment.columns = [\n",
    "    \"FIPS_Code\", \"State\", \"Area_Name\",\n",
    "    \"Civilian_labor_force_2020\", \"Unemployed_2020\", \"Unemployment_rate_2020\",\n",
    "    \"Civilian_labor_force_2021\", \"Unemployed_2021\", \"Unemployment_rate_2021\",\n",
    "    \"Civilian_labor_force_2022\", \"Unemployed_2022\", \"Unemployment_rate_2022\",\n",
    "    \"Civilian_labor_force_2023\", \"Unemployed_2023\", \"Unemployment_rate_2023\"\n",
    "]\n",
    "\n",
    "merged_data = pd.merge(cleaned_data, unemployment, on=\"Area_Name\", how=\"inner\")\n",
    "\n",
    "merged_data.dropna(inplace=True)\n",
    "\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f79fc7-a8f5-47fb-ae73-3ae64437668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"PopulationEstimates.xlsx\"  # Replace with the path to your file\n",
    "population = pd.read_excel(file_path, sheet_name=0)\n",
    "# Remove the first 4 rows and reset column headers\n",
    "population = population.iloc[3:]\n",
    "population.columns = population.iloc[0]  # Set the first row as column headers\n",
    "population = population[1:]  \n",
    "\n",
    "population.columns = population.columns.str.strip()\n",
    "population = population.reset_index(drop=True)  # Reset the index\n",
    "\n",
    "\n",
    "columns_to_keep = [\"Area_Name\", \"FIPStxt\"]\n",
    "population_columns = [col for col in population.columns if \"POP_ESTIMATE_\" in col]\n",
    "columns_to_keep += population_columns\n",
    "\n",
    "filtered_data = population[columns_to_keep]\n",
    "\n",
    "filtered_data.rename(\n",
    "    columns={\n",
    "        f\"POP_ESTIMATE_{year}\": f\"Population_{year}\" for year in [\"2020\", \"2021\", \"2022\", \"2023\"]\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88cde55-0452-4cc6-a910-1200c715e095",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_data[\"FIPS_Code\"] = merged_data[\"FIPS_Code\"].astype(str)\n",
    "filtered_data[\"FIPStxt\"] = filtered_data[\"FIPStxt\"].astype(str)\n",
    "\n",
    "final_data = pd.merge(merged_data, filtered_data, left_on=\"FIPS_Code\", right_on=\"FIPStxt\", how=\"inner\")\n",
    "final_data.dropna(inplace=True)\n",
    "\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226227e0-3799-4303-923d-7d5cc034e2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37a01f3-4d48-46ae-a481-bcd92d27e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = final_data.loc[:, ~final_data.columns.duplicated()]\n",
    "\n",
    "if 'Area_Name_x' in df.columns:\n",
    "    df.rename(columns={'Area_Name_x': 'Area_Name'}, inplace=True)\n",
    "if 'FIPS_Code' in df.columns:\n",
    "    df.rename(columns={'FIPS_Code': 'FIPS_Code'}, inplace=True)\n",
    "if 'State' in df.columns:\n",
    "    df.rename(columns={'State': 'State'}, inplace=True)\n",
    "\n",
    "df.drop(columns=['Area_Name_y', 'FIPStxt'], errors='ignore', inplace=True)\n",
    "\n",
    "columns_order = ['Area_Name', 'FIPS_Code', 'State'] + [col for col in df.columns if col not in ['Area_Name', 'FIPS_Code', 'State']]\n",
    "df = df[columns_order]\n",
    "\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a9d0f-e6c9-4e5d-b3e5-eb35c1e42c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a81ab1a-417c-4c65-b894-f35e3dbea9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, regexp_replace\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"ConvertColumnsToDouble\").getOrCreate()\n",
    "\n",
    "# Sample data creation\n",
    "# Replace this with loading your actual data\n",
    "# Assuming `df` is your Pandas DataFrame already loaded\n",
    "for column in df.columns:\n",
    "    if df[column].dtype in [\"int64\", \"float64\"]:\n",
    "        df[column] = df[column].astype(float)\n",
    "    elif df[column].dtype == \"object\":\n",
    "        df[column] = df[column].astype(str)\n",
    "\n",
    "# Create Spark DataFrame from the Pandas DataFrame\n",
    "data = spark.createDataFrame(df)\n",
    "\n",
    "# Define the list of columns to be converted to double\n",
    "columns_to_convert = [\n",
    "    'gdp_2020', 'gdp_2021', 'gdp_2022', 'gdp_2023',\n",
    "    'Civilian_labor_force_2020', 'Unemployed_2020', 'Unemployment_rate_2020',\n",
    "    'Civilian_labor_force_2021', 'Unemployed_2021', 'Unemployment_rate_2021',\n",
    "    'Civilian_labor_force_2022', 'Unemployed_2022', 'Unemployment_rate_2022',\n",
    "    'Civilian_labor_force_2023', 'Unemployed_2023', 'Unemployment_rate_2023',\n",
    "    'Population_2020', 'Population_2021', 'Population_2022', 'Population_2023'\n",
    "]\n",
    "\n",
    "# Replace commas with empty strings and cast columns to double\n",
    "for column in columns_to_convert:\n",
    "    data = data.withColumn(column, regexp_replace(col(column), \",\", \"\"))\n",
    "    data = data.withColumn(column, col(column).cast(\"double\"))\n",
    "\n",
    "# Display the schema to verify types\n",
    "data.printSchema()\n",
    "\n",
    "# Show a sample of the data to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c3626-c9e0-4343-bd49-5dca3c0b5423",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d73b4d0-628b-4f00-ab7e-15e63d75b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to convert to float\n",
    "columns_to_cast = [\n",
    "    \"gdp_2020\",\"gdp_2021\",\"gdp_2022\",\"gdp_2023\", \n",
    "    \"Civilian_labor_force_2020\", \"Unemployed_2020\", \"Unemployment_rate_2020\",\n",
    "    \"Civilian_labor_force_2021\", \"Unemployed_2021\", \"Unemployment_rate_2021\",\n",
    "    \"Civilian_labor_force_2022\", \"Unemployed_2022\", \"Unemployment_rate_2022\",\n",
    "    \"Civilian_labor_force_2023\", \"Unemployed_2023\", \"Unemployment_rate_2023\",\n",
    "    \"Population_2020\", \"Population_2021\", \"Population_2022\", \"Population_2023\"\n",
    "]\n",
    "\n",
    "# Convert columns to float\n",
    "for column in columns_to_cast:\n",
    "    if column in df.columns:\n",
    "        # Handle missing values, commas, and non-numeric characters\n",
    "        df[column] = df[column].replace({',': ''}, regex=True).replace('', '0').astype(float)\n",
    "    else:\n",
    "        print(f\"Warning: Column {column} does not exist in the DataFrame\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4584ddea-30fd-47b5-a56f-7dc8bc77159a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b2c24-3dc6-49cd-836b-b4f9ae873c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"UnemploymentRatePrediction\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark_df = spark.createDataFrame(df)\n",
    "\n",
    "feature_columns = [\n",
    "    \"gdp_2020\", \"gdp_2021\", \"gdp_2022\",\n",
    "    \"Civilian_labor_force_2020\", \"Civilian_labor_force_2021\", \"Civilian_labor_force_2022\",\n",
    "    \"Population_2020\", \"Population_2021\", \"Population_2022\"\n",
    "]\n",
    "label_column = \"Unemployment_rate_2023\"\n",
    "\n",
    "agg_exprs = [F.avg(c).alias(f\"avg_{c}\") for c in feature_columns + [label_column]]\n",
    "state_means = spark_df.groupBy(\"State\").agg(*agg_exprs)\n",
    "\n",
    "spark_df = spark_df.join(state_means, on=\"State\", how=\"left\")\n",
    "for c in feature_columns + [label_column]:\n",
    "    spark_df = spark_df.withColumn(c, F.coalesce(F.col(c), F.col(f\"avg_{c}\")))\n",
    "\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "df_assembled = assembler.transform(spark_df)\n",
    "\n",
    "train_df, test_df = df_assembled.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=label_column)\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "# \n",
    "predictions_test = lr_model.transform(test_df)\n",
    "evaluator = RegressionEvaluator(labelCol=label_column, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions_test)\n",
    "r2_evaluator = RegressionEvaluator(labelCol=label_column, predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = r2_evaluator.evaluate(predictions_test)\n",
    "\n",
    "print(f\"Test RMSE: {rmse}\")\n",
    "print(f\"Test R2: {r2}\")\n",
    "\n",
    "# \n",
    "all_predictions = lr_model.transform(df_assembled)\n",
    "\n",
    "# \n",
    "all_count = all_predictions.count()\n",
    "print(f\"Number of rows in all_predictions: {all_count}\")\n",
    "\n",
    "all_predictions.select(\"Area_Name\", \"FIPS_Code\", label_column, \"prediction\").show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c321ad-6516-4110-8c00-c49e83ab6184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# # Get the active Spark session\n",
    "# spark = SparkSession.getActiveSession()\n",
    "\n",
    "# # Stop the Spark session if it's active\n",
    "# if spark:\n",
    "#     spark.stop()\n",
    "#     print(\"All Spark sessions have been successfully closed.\")\n",
    "# else:\n",
    "#     print(\"No active Spark sessions found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8feec9-e0ce-4a38-9f8b-25db0107578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, abs, expr\n",
    "\n",
    "predictions_with_error = all_predictions.withColumn(\n",
    "    \"absolute_error\",\n",
    "    abs(col(\"prediction\") - col(label_column))\n",
    ")\n",
    "\n",
    "predictions_with_error.select(\"Area_Name\", label_column, \"prediction\", \"absolute_error\").show(50, truncate=False)\n",
    "\n",
    "mae = predictions_with_error.selectExpr(\"avg(abs(prediction - Unemployment_rate_2023)) as MAE\").collect()[0][\"MAE\"]\n",
    "print(f\"Test MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5640ce3-80b5-4c33-b3f4-e07d85087394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "predictions_pdf = all_predictions.select(\"Area_Name\", label_column, \"prediction\").toPandas()\n",
    "\n",
    "fig = px.scatter(\n",
    "    predictions_pdf, \n",
    "    x=label_column, \n",
    "    y=\"prediction\", \n",
    "    hover_data=[\"Area_Name\"],\n",
    "    title=\"Predicted vs Actual Unemployment Rate (2023)\",\n",
    "    labels={\n",
    "        label_column: \"Actual Unemployment Rate (2023)\",\n",
    "        \"prediction\": \"Predicted Unemployment Rate (2023)\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# \n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=predictions_pdf[label_column].min(),\n",
    "    y0=predictions_pdf[label_column].min(),\n",
    "    x1=predictions_pdf[label_column].max(),\n",
    "    y1=predictions_pdf[label_column].max(),\n",
    "    line=dict(color=\"Red\", dash=\"dot\"),\n",
    "    name=\"Ideal Prediction Line\"\n",
    ")\n",
    "\n",
    "# \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b1dcc1-ead4-48df-b6cb-fd778c135550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f38961-da07-4808-a1e9-48e038584ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1bb821-bb54-4ea2-9efe-9e5904d3d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import requests, json\n",
    "\n",
    "predictions_pdf = all_predictions.select(\"FIPS_Code\", \"prediction\", \"Unemployment_rate_2023\").toPandas()\n",
    "\n",
    "predictions_pdf[\"FIPS_Code\"] = predictions_pdf[\"FIPS_Code\"].astype(str).str.zfill(5)\n",
    "predictions_pdf[\"error\"] = predictions_pdf[\"prediction\"] - predictions_pdf[\"Unemployment_rate_2023\"]\n",
    "\n",
    "counties_url = \"https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json\"\n",
    "counties = json.loads(requests.get(counties_url).text)\n",
    "\n",
    "fig = px.choropleth(\n",
    "    predictions_pdf,\n",
    "    geojson=counties,\n",
    "    locations='FIPS_Code',\n",
    "    color='error',\n",
    "    color_continuous_scale=[\"#0000FF\", \"#FFFFFF\", \"#FF0000\"],\n",
    "    color_continuous_midpoint=0,\n",
    "    range_color=(-2, 2),\n",
    "    scope=\"usa\",\n",
    "    labels={'error':'Prediction Error'}\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"County-level Unemployment Rate Prediction Error (2023)\",\n",
    "    margin={\"r\":0,\"t\":30,\"l\":0,\"b\":0},\n",
    "    width=1200,\n",
    "    height=800\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e00077-103f-4562-9d2f-1b3d5b3edb87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bigdata-spark]",
   "language": "python",
   "name": "conda-env-bigdata-spark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
